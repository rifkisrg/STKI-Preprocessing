{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "STKI Tugas 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sxHFt8FxVeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LubjmqHxVec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "current = time()\n",
        "\n",
        "def preprocessing(docs):\n",
        "    cleaned = re.sub(\"[^a-zA-Z\\s]+\", \" \", docs)\n",
        "    folded = cleaned.lower()\n",
        "    token = re.findall(\"[^\\\\s0-9][A-Za-z]+\", folded)\n",
        "    \n",
        "    kata = \" \".join(token)\n",
        "    \n",
        "    return kata\n",
        "\n",
        "def preprocessingKalimat(docs):\n",
        "    # cleaning semua kecuali isi tag <TITLE> dan <TEXT>\n",
        "    cleaned = re.sub(\"<.*?>(\\w+-[0-9]{0,90}|\\d{2,90})?\", \" \", docs)\n",
        "    token = re.findall(\"(.*?)(\\. |\\n)\", cleaned)\n",
        "    return token\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBoU8a3exVeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "7446cdbd-0f8a-4702-884a-709bd7a0ef30"
      },
      "source": [
        "f = open(\"corpus.txt\", 'r', encoding='ansi').read()\n",
        "kalimat = f\n",
        "\n",
        "korpus = []\n",
        "total_token = Counter()\n",
        "\n",
        "titles = re.findall(\"<TITLE>(.*?)<\\/TITLE>\", f, re.DOTALL)\n",
        "texts = re.findall(\"<TEXT>(?:[a-zA-Z0-9,\\n]*[.com, ]*)?(.*?)<\\/TEXT>\", f, re.DOTALL)\n",
        "\n",
        "for title, text in zip(titles, texts):\n",
        "    korpus.append({'TITLE': title, 'TEXT': text})\n",
        "# print(korpus)\n",
        "    \n",
        "for korp in korpus:\n",
        "    korp['TITLE'] = preprocessing(korp['TITLE'])\n",
        "    korp['PREPPED_TEXT'] = preprocessing(korp['TEXT'])\n",
        "    korp['TOKEN'] = f\"{korp['TITLE']} {korp['PREPPED_TEXT']}\".split()\n",
        "\n",
        "    korp['count'] = Counter(korp['TOKEN'])\n",
        "    total_token += korp ['count']\n",
        "    \n",
        "# print(total_token)\n",
        "print(korpus[:20])\n",
        "\n",
        "total = [ttl for ttl in total_token.values()]\n",
        "print(sum(total))\n",
        "print(total_token.most_common(20))\n",
        "print(type(total_token))\n",
        "\n",
        "unik = [unik for unik in total_token.keys()]\n",
        "print(len(unik))\n",
        "# unik"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2f4e1f33cbd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"corpus.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ansi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'corpus.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDEPurrvxVel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(korpus.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBTzgE3mxVeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def frek_dibawah_sepuluh(total_token):\n",
        "    sum_len = [val for val in total_token.values() if val < 10]\n",
        "    return len(sum_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22V255ClxVeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frek_dibawah_sepuluh(total_token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEbXuTcmxVex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def muncul_seluruh_dokumen(korpus, kata_unik):\n",
        "    kata = []\n",
        "    for un in unik:\n",
        "        ditemukan_di_seluruh_dokumen = True\n",
        "        for korp in korpus:\n",
        "            if un not in korp['TOKEN']:\n",
        "                ditemukan_di_seluruh_dokumen = False\n",
        "                break\n",
        "        \n",
        "        if ditemukan_di_seluruh_dokumen:\n",
        "            kata.append(un)\n",
        "            \n",
        "    return kata\n",
        "\n",
        "print(len(muncul_seluruh_dokumen(korpus, unik)))       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeRUDwi1xVe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def muncul_50_dokumen(korpus, total_kata_unik):\n",
        "#     kata = []\n",
        "#     for unik in total_kata_unik.keys():\n",
        "#         for korp in korpus:\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFCckDj4xVe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"new-kata-dasar.txt\", 'r') as kata:\n",
        "    katdas = kata.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJiGGgOoxVe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cari_imbuhan_kan(kata_unik, katdas):\n",
        "    kata_dasar = []\n",
        "    gabungan_kata_unik = \" \".join(unik)\n",
        "    reg = re.findall(r\"[A-Za-z]+kan\\b\", gabungan_kata_unik)\n",
        "    \n",
        "    for word in reg:\n",
        "        if word in katdas:\n",
        "            reg.remove(word)\n",
        "        else:\n",
        "            kata_dasar.append(word)\n",
        "    return len(set(kata_dasar))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsrYo3jSxVe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cari_imbuhan_kan(unik, katdas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPcT9zFSxVfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Distribusi Zipf\n",
        "\n",
        "counter_gambar = dict(total_token.most_common(10))\n",
        "\n",
        "x = [token for token in counter_gambar.keys()]\n",
        "y = [jumlah for jumlah in counter_gambar.values()]\n",
        "\n",
        "plt.plot(x,y)\n",
        "plt.xlabel('Token')\n",
        "plt.ylabel('Jumlah')\n",
        "plt.title('Distribusi Zipf')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODS6RpgJzp2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cariKalimat(corpus):\n",
        "    kalimat = []\n",
        "    tes = preprocessingKalimat(corpus)\n",
        "    for i in range(len(tes)):\n",
        "        for j in range(len(tes[i])):\n",
        "            if len(tes[i][j]) > 3:\n",
        "                kalimat.append(tes[i][j])\n",
        "            else: pass\n",
        "    return len(kalimat)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqoYSc1-xVfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Pertanyaan\")\n",
        "print(\"a. Banyak dokumen dalam korpus : \", len(korpus))\n",
        "print(\"b. 20 kata dengan frekuensi tertinggi : \", total_token.most_common(20))\n",
        "print(\"c. 20 kata muncul di seluruh dokumen : \", len(muncul_seluruh_dokumen(korpus, unik)))\n",
        "print(\"d. 10 kata hanya muncul di 50 dokumen : \", cariKalimat(kalimat))\n",
        "# print(\"e. Distribusi zipf : \", gambar)\n",
        "print(\"f. Jumlah kata dengan frekuensi kurang dari 10 : \", frek_dibawah_sepuluh(total_token))\n",
        "print(\"g. Total seluruh kata dalam korpus : \", sum(total))\n",
        "print(\"h. Jumlah kata unik dalam korpus : \", len(unik))\n",
        "print(\"i. Jumlah kata unik berimbuhan ber- : \")\n",
        "print(\"j. Jumlah kata unik berimbuhan -kan : \", cari_imbuhan_kan(unik, katdas))\n",
        "print(\"k. Jumlah kalimat dalm korpus : \")\n",
        "print(\"l. Total frekuensi frase : \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL-Loj5AxVfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(time() - current)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}